# (no work)

I don't think there's work for the CLI in these things:  
‚≠ê `ai` CLI (no work) ‚¨ú: CF1.6 - Canonical L200 getting started sample project for starting with python code using Semantic Kernel  
‚≠ê `ai` CLI (no work) ‚¨ú: CF1.7 - Azure AI samples repo  
‚≠ê `ai` CLI (no work) ‚¨ú: CF3.1 - Resolve any naming concerns with ‚Äúlogic app flows‚Äù  
‚≠ê `ai` CLI (no work) ‚¨ú: CF3.6 - The promptflow runtime and vs code share the same default curated environment  
‚≠ê `ai` CLI (no work) ‚¨ú: CF3.8 - Stretch: remove the runtime concept from promptflow  
‚≠ê `ai` CLI (no work) ‚¨ú: CF8.1 - Folder structure  
‚≠ê `ai` CLI (no work) ‚¨ú: CF8.2 - Custom environments  
‚≠ê `ai` CLI (no work) ‚¨ú: CF8.3 - Stretch: I can add repos to my project so that VS Code can clone/open those repos directly  

# DONE

I think these are completely done:  
‚≠ê `ai` CLI DONE ‚úÖ (debian): CF1.1 - I can easily and quickly install the CLI and  SDK with a single command, and it installs quickly with minimal dependencies    
‚≠ê `ai` CLI DONE ‚úÖ (docker): CF1.1 - I can easily and quickly install the CLI and  SDK with a single command, and it installs quickly with minimal dependencies    
‚≠ê `ai` CLI DONE ‚úÖ (ubuntu): CF1.1 - I can easily and quickly install the CLI and  SDK with a single command, and it installs quickly with minimal dependencies    
‚≠ê `ai` CLI DONE ‚úÖ: CF1.9  - Setup and Management  

# DONE/definitely need more work

I think these things are "done", but need a bit more work. That work is completely or mostly unblocked:  
‚≠ê `ai` CLI DONE ‚úÖ?üü®: (need to revise ??) CF2.2 - I can create a new hub/project with all of the resources and models I need  
‚≠ê `ai` CLI DONE ‚úÖ?üü®: (need to revise ??) CF4.7 - Stretch: Project Wednesday: inferencing API leverages Azure AI concepts  
‚≠ê `ai` CLI DONE ‚úÖ?üü®: (need to revise ??) CF6.4 - I can set the default chat and embedding deployments from a CLI/SDK call  

# DONE/might need more work

I think these things are "done", but might need a bit more work. Without additional guidance, these are blocked by the need for more clarity:  
‚≠ê `ai` CLI TODO ‚úÖ!üüß: (need spec/clarity)  CF4.3 - Project Weds: pre-processing API built on unified platform  
‚≠ê `ai` CLI TODO ‚úÖ!üüß: (need spec/clarity) CF2.1 - I can create a project that uses existing resources (in project setup)  

# CUT

I think these things are clearly cut for Ignite:  
‚≠ê `ai` CLI TODO ‚èπÔ∏è ‚óºÔ∏è: CF4.6 - Stretch: I can configure datasets/indexes to refresh periodically with latest data  
‚≠ê `ai` CLI TODO ‚èπÔ∏è ‚óºÔ∏è: CF5.7 - Out of scope: custom evaluators from the SDK (use promptflow?)  
‚≠ê `ai` CLI TODO ‚èπÔ∏è ‚óºÔ∏è: CF6.3 - Improve experience of deploying models from the model catalog  

# TODO (unblocked)

I think these things are unblocked and ready to be worked on:  
‚≠ê `ai` CLI TODO ‚èπÔ∏è (alpine): CF1.1 - I can easily and quickly install the CLI and  SDK with a single command, and it installs quickly with minimal dependencies    
‚≠ê `ai` CLI TODO ‚èπÔ∏è (macOS): CF1.1 - I can easily and quickly install the CLI and  SDK with a single command, and it installs quickly with minimal dependencies    
‚≠ê `ai` CLI TODO ‚èπÔ∏è (windows): CF1.1 - I can easily and quickly install the CLI and  SDK with a single command, and it installs quickly with minimal dependencies    
‚≠ê `ai` CLI TODO ‚èπÔ∏è: CF1.3 - CLI/SDK can get information from the project without storing additional local metadata  
‚≠ê `ai` CLI TODO ‚èπÔ∏è: CF1.5 - E2E Tests for langchain and SDK - We don‚Äôt need to manually test the demo repo every time we update package dependencies   
‚≠ê `ai` CLI TODO ‚èπÔ∏è: CF1.8 - CLI/SDK Reference Docs  
‚≠ê `ai` CLI TODO/p2 üî≤: CF1.2 - We have a Generative AI SDK for C# that can be used by the Azure AI CLI   
‚≠ê `ai` CLI TODO/p2 üî≤: CF1.4 - Telemetry - We have a basic telemetry dashboard for CLI/SDK usage (best effort): calls that were made, success/failure  

# TODO (need spec/clarity)

I think these things are blocked by the need for more clarity:
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üü®: (need spec/clarity)  CF4.2 - I can build MLIndex with minimal local dependencies using the CLI/SDK  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF2.3 - I can easily connect my development environment to an existing project  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF3.2 - I can use the ai cli instead of the pf cli (so that I only need to use one CLI)  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF3.3 - Running a flow locally uses connections from the project  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF3.4 - I can manage flows via SDK/CLI and transition between code and Studio  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF3.5 - I can more easily wrap my existing python code (custom/langchain/sdk) in a promptflow  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF4.1  - I can do dataset CRUD using the AI CLI/SDK  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF4.4 - I can build indexes using Fabric as a datasource  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF4.5 - I can build an index in the cloud using project compute  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF5.1 - Prompts are logged to the evaluation result when they are passed as input parameters  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF5.2 - Users can run our built-in evaluations on local flows with the default SDK/CLI installation  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF5.3 - Conversation simulator  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF5.4 - Dataset generator  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF5.5 - Users can ingest evaluation outputs directly from CLI/SDK outputs so that they can use evaluation in their test/automation code  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF5.6 - Stretch: Users can run an evaluation remotely  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF6.1 - I can deploy promptflows to the project (MIR), including ones that wrap langchain/SK, using AI CLI/SDK  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF6.2 - I can consume a deployed promptflow using the chat flow SDK  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF6.5 - Generate a docker file and/or bicep template (stretch) that can be used to deploy the flow into production  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF6.6 - Can enable content safety filter on OSS model deployment  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF6.7 - Can enable default monitor (MDC+default GSQ template) during flow deployment creation  
‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF7.1 - When fine tuning OAI models in my AI project using the OpenAI SDK, the fine tuning metrics are logged /visible to the project  

See below for more information on the status of each item.

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üü®: (need spec/clarity)  CF4.2 - I can build MLIndex with minimal local dependencies using the CLI/SDK  

**QUESTIONS:**
- If the CLI switches to use build_mlindex, is that all that's needed? 
- What are the key scenarios we want to ensure are in the CLI? 
- Build using cloud compute vs local compute? Which is the priority for Ignite? 

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF2.3 - I can easily connect my development environment to an existing project  

From the spec:
> Need to simplify this so that user just selects the project 

**QUESTIONS:**
- Do you mean in the `ai init` scenario when they select "Resource + Project"?
- Meaning ... We configure everything else needed to do `ai chat`, `ai flow`, ...?

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF3.2, CF 3.3, CF 3.4, CF 3.5, CF 5.1, CF 5.2, CF 5.5, CF 5.6, CF 6.1, CF 6.2

üìÉ Leah is working on a spec to cover all this:
- CF3.3 - Running a flow locally uses connections from the project  
- CF3.4 - I can manage flows via SDK/CLI and transition between code and Studio  
- CF3.5 - I can more easily wrap my existing python code (custom/langchain/sdk) in a promptflow  
- CF5.1 - Prompts are logged to the evaluation result when they are passed as input parameters  
- CF5.2 - Users can run our built-in evaluations on local flows with the default SDK/CLI installation  
- CF5.5 - Users can ingest evaluation outputs directly from CLI/SDK outputs so that they can use evaluation in their test/
automation code  
- CF5.6 - Stretch: Users can run an evaluation remotely  
- CF6.1 - I can deploy promptflows to the project (MIR), including ones that wrap langchain/SK, using AI CLI/SDK  
- CF6.2 - I can consume a deployed promptflow using the chat flow SDK  

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF4.1 - I can do dataset CRUD using the AI CLI/SDK  

**SPEC NEEDED** ‚ö†Ô∏è

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI? Is it me? 
- When will the SDK be done enough I can try to implement?
- How will this work with other facilities in the CLI?

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF4.4 - I can build indexes using Fabric as a datasource  

**SPEC NEEDED** ‚ö†Ô∏è

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI? Is it me?
- When will the SDK be done enough I can try to implement?
- How will this work with other facilities in the CLI?

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF4.5 - I can build an index in the cloud using project compute  

**SPEC NEEDED** ‚ö†Ô∏è

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI? is it me?
- When will the SDK be done enough I can try to implement?

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF5.3 - Conversation simulator  

**SPEC NEEDED** ‚ö†Ô∏è

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI? Is it me?
- When will the SDK be done enough I can try to implement?
- How will this work with other facilities in the CLI?

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF5.4 - Dataset generator  

**SPEC NEEDED** ‚ö†Ô∏è

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI? Is it me?
- When will the SDK be done enough I can try to implement?
- How will this work with other facilities in the CLI?

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF6.5 - Generate a docker file and/or bicep template (stretch) that can be used to deploy the flow into production  

**SPEC NEEDED** ‚ö†Ô∏è ... maybe ... 

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI? Is it me? Is there any work?
- How will this work with other facilities in the CLI?


## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF6.6 - Can enable content safety filter on OSS model deployment  

**SPEC NEEDED** ‚ö†Ô∏è ... maybe ... 

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI?
- How will this work with other facilities in the CLI?

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF6.7 - Can enable default monitor (MDC+default GSQ template) during flow deployment creation  

**SPEC NEEDED** ‚ö†Ô∏è ... maybe ... 

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI?
- How will this work with other facilities in the CLI?

## ‚≠ê `ai` CLI TODO ‚èπÔ∏è!üüß: (need spec/clarity)  CF7.1 - When fine tuning OAI models in my AI project using the OpenAI SDK, the fine tuning metrics are logged /visible to the 
project  

**SPEC NEEDED** ‚ö†Ô∏è ... maybe ... 

**QUESTIONS:**
- Who is working on this spec for the CLI?
- Who will implement this work for the CLI?
- How will this work with other facilities in the CLI?
