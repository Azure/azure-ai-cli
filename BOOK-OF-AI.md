# AI CLI

Let's do a quick tour of the various AI capabilities available in Azure via the new Azure AI CLI (`ai`). 

**INSTALLATION and SETUP**  
[CHAPTER 1: CLI Installation](#chapter-1-cli-installation)  
[CHAPTER 2: Setup w/ Azure OpenAI](#chapter-2-setup-w-azure-openai)  

**OPENAI CHAT COMPLETIONS**  
[CHAPTER 3: Chat Completion Basics](#chapter-3-openai-chat-completions-basics)  
[CHAPTER 4: Chat Completions w/ Function Calling](#chapter-4-openai-chat-completions-w-function-calling)  
[CHAPTER 5: Chat Completions w/ RAG + AI Search](#chapter-5-openai-chat-completions-w-rag--ai-search)  

**OPENAI ASSISTANTS API**  
[CHAPTER 6: Assistants API](#chapter-6-openai-assistants-api)  
[CHAPTER 7: Assistants Basics](#chapter-7-openai-assistants-basics)  
[CHAPTER 8: Assistants w/ Code Interpreter](#chapter-8-openai-assistants-w-code-interpreter)  
[CHAPTER 9: Assistants w/ Function Calling](#chapter-9-openai-assistants-w-function-calling)  
[CHAPTER 10: Assistants w/ File Search](#chapter-10-openai-assistants-w-file-search)  

**GITHUB MODEL MARKETPLACE**  
[CHAPTER 11: Setup w/ GitHub Model Marketplace](#chapter-11-setup-w-github-model-marketplace)  
[CHAPTER 12: GitHub Model Chat Completion Basics](#chapter-12-github-model-chat-completion-basics)  
[CHAPTER 13: GitHub Model Chat Completions W/ Function Calling](#chapter-13-github-model-chat-completions-w-function-calling)üöß  

**AZURE AI INFERENCING**  
[CHAPTER 14: Setup w/ AI Studio and the Model Catalog](#chapter-14-setup-w-ai-studio-and-the-model-catalog)  
[CHAPTER 15: AI Studio Chat Completions Basics](#chapter-15-ai-studio-chat-completions-basics)  
[CHAPTER 16: AI Studio Chat Completions w/ Function Calling](#chapter-16-ai-studio-chat-completions-w-function-calling)üöß  

**LOCAL INFERENCING W/ ONNX AND PHI-3**  
[CHAPTER 17: PHI-3 Models](#chapter-17-phi-3-models)  
[CHAPTER 18: ONNX Chat Completions](#chapter-18-onnx-chat-completions)  
[CHAPTER 19: ONNX Chat Completions w/ Function Calling](#chapter-19-onnx-chat-completions-w-function-calling)  

**SPEECH INPUT AND OUTPUT**  
[CHAPTER 20: Speech Synthesis](#chapter-20-speech-synthesis)  
[CHAPTER 21: Speech Recognition](#chapter-21-speech-recognition)    
[CHAPTER 22: Speech Translation](#chapter-22-speech-translation)    
[CHAPTER 23: Speech Recognition w/ Keyword Spotting](#chapter-23-speech-recognition-w-keyword-spotting)  

**MULTI-MODAL AI**  
[CHAPTER 24: Multi-Modal AI](#chapter-24-multi-modal-ai)  
[CHAPTER 25: Chat Completions w/ Speech Input](#chapter-25-chat-completions-w-speech-input)  
[CHAPTER 26: Chat Completions w/ Speech Input and Output](#chapter-26-chat-completions-w-speech-input-and-output)  
[CHAPTER 27: Chat Completions w/ Image Input](#chapter-27-chat-completions-w-image-input)  
[CHAPTER 28: Chat Completions w/ Image Output](#chapter-28-chat-completions-w-image-output)  

**SEMANTIC KERNEL AGENTS**  
[CHAPTER 29: Semantic Kernel Basics](#chapter-29-semantic-kernel-basics)  
[CHAPTER 30: Semantic Kernel w/ Function Calling](#chapter-30-semantic-kernel-w-function-calling)  
[CHAPTER 31: Semantic Kernel w/ Basic Agents](#chapter-31-semantic-kernel-w-basic-agents)  
[CHAPTER 32: Semantic Kernel w/ Advanced Agents](#chapter-32-semantic-kernel-w-advanced-agents)  

## CHAPTER 1: CLI Installation

‚û°Ô∏è [**CLI Installation**](#chapter-1-cli-installation)  

‚ó¶ Install the pre-requisites for the Azure AI CLI (`ai`)  
‚ó¶ `winget install Microsoft.DotNet.SDK.8`  

‚ó¶ Install the Azure AI CLI (`ai`) on Linux, Mac, or Windows  
‚ó¶ `dotnet tool install -g Microsoft.Azure.AI.CLI --prerelease`  

‚ó¶ OR: Use the Azure AI CLI (`ai`) in a GitHub Codespace  
‚ó¶ OR: Use the Azure AI CLI (`ai`) in a Docker container  

## CHAPTER 2: Setup w/ Azure OpenAI

‚û°Ô∏è [**Setup w/ Azure OpenAI**](#chapter-2-setup-w-azure-openai)  

‚ó¶ `ai init openai`  
‚ó¶ Select your Azure subscription  
‚ó¶ Select or create your Azure OpenAI resource  
‚ó¶ Select or create an OpenAI chat model deployment (e.g. gpt-4o)  
‚ó¶ Select or create an OpenAi embeddings model deployment  

## CHAPTER 3: OpenAI Chat Completions Basics

‚û°Ô∏è [**OpenAI Chat Completion Basics**](#chapter-3-openai-chat-completions-basics)  

üõë Setup w/ Azure OpenAI in [chapter 2](#chapter-2-setup-w-azure-openai)  

‚ó¶ System prompts, user input, interactive chats w/ history  
‚ó¶ `ai chat --user "What is the capital of France?"`  
‚ó¶ `ai chat --interactive`  
‚ó¶ `ai chat --interactive --system @prompt.txt`  
‚ó¶ `ai chat --interactive --system @prompt.txt --user "Tell me a joke"`  
‚ó¶ `ai chat --interactive --output-answer answer.txt`  
‚ó¶ `ai chat --interactive --output-chat-history history.jsonl`  
‚ó¶ `ai chat --interactive --input-chat-history history.jsonl`  

‚ó¶ Generate console apps for chat completions  
‚ó¶ `ai dev new list`  
‚ó¶ `ai dev new list chat`  
‚ó¶ `ai dev new openai-chat --csharp` or `--python` or `--javascript` ...  
‚ó¶ `ai dev new openai-chat-streaming --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... getting connection info/secrets from environment variables  
‚ó¶ ... using a helper class to encapsulate the OpenAI API calls  
‚ó¶ ... getting input from the user  
‚ó¶ ... sending the input to the helper class  
‚ó¶ ... getting the response from the helper class  
‚ó¶ ... deeper dive into the helper class  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

## CHAPTER 4: OpenAI Chat Completions w/ Function Calling

‚û°Ô∏è [**OpenAI Chat Completions w/ Function Calling**](#chapter-4-openai-chat-completions-w-function-calling)  

üõë Setup w/ Azure OpenAI in [chapter 2](#chapter-2-setup-w-azure-openai)  

‚ó¶ Extending the LLM's world knowledge with functions  
‚ó¶ `ai chat --user "What time is it?"` => doesn't know the time  
‚ó¶ `ai chat --user "What time is it?" --built-in-functions` => works!  
‚ó¶ `ai chat --user "What is in the README.md file?" --built-in-functions`  

‚ó¶ Allowing the LLM to interact with your code  
‚ó¶ `ai chat --user "Save the pledge of allegiance to 'pledge.txt'"` => doesn't work  
‚ó¶ `ai chat --user "Save the pledge of allegiance to 'pledge.txt'" --built-in-functions` => works!  

‚ó¶ Generating code for function calling  
‚ó¶ `ai dev new list function`  
‚ó¶ `ai dev new openai-chat-streaming-with-functions --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... builds on previous chapter's console app  
‚ó¶ ... see how functions are defined, given to "function factory"  
‚ó¶ ... in helper class, see how functions are given to the LLM  
‚ó¶ ... see how the LLM streams back the function call requests  
‚ó¶ ... see how the helper class processes the function call responses  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

## CHAPTER 5: OpenAI Chat Completions w/ RAG + AI Search

‚û°Ô∏è [**OpenAI Chat Completions w/ RAG + AI Search**](#chapter-5-openai-chat-completions-w-rag--ai-search)  

üõë Setup w/ Azure OpenAI in [chapter 2](#chapter-2-setup-w-azure-openai)  

‚ó¶ `ai init search`  
‚ó¶ Select your Azure subscription  
‚ó¶ Select or create your Azure AI Search resource  

‚ó¶ Create or update your Azure AI Search index  
‚ó¶ `ai search index create --name MyFiles --files *.md --blob-container https://...`  
‚ó¶ `ai search index update --name MyFiles --files *.md --blob-container https://...`  

‚ó¶ Use the RAG model to search your AI Search index  
‚ó¶ `ai chat --user "What is the capital of France?" --index MyFiles`  

‚ó¶ Generate code for RAG + AI Search  
‚ó¶ `ai dev new openai-chat-streaming-with-data --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... builds on Chapter 4's console app  
‚ó¶ ... see how the helper class gives the LLM access to the AI Search index  
‚ó¶ ... see how the LLM sends back citations to the helper class  
‚ó¶ ... see how the helper class processes the citations  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

## CHAPTER 6: OpenAI Assistants API

‚û°Ô∏è [OpenAI Assistants API](#chapter-6-openai-assistants-api)  

üõë Setup w/ Azure OpenAI in [chapter 2](#chapter-2-setup-w-azure-openai)  

‚ó¶ Differences between chat completions and assistants  
‚ó¶ ... stateless vs stateful  
‚ó¶ ... customer controlled chat history vs threads  
‚ó¶ ... automatic context window management  
‚ó¶ ... advanced features: code interpreter, function calling, file search  

‚ó¶ Listing, creating, updating, and deleting assistants  
‚ó¶ `ai chat assistant`  
‚ó¶ `ai chat assistant list`  
‚ó¶ `ai chat assistant create --name MyAssistant`  
‚ó¶ `ai chat assistant update --instructions @instructions.txt`  
‚ó¶ `ai chat assistant delete --id ID`  

‚ó¶ Creating assistant saves the ID to the config  
‚ó¶ `ai config @assistant.id`  

‚ó¶ Clearing the assistant ID from the config  
‚ó¶ `ai config --clear assistant.id`  

## CHAPTER 7: OpenAI Assistants Basics

‚û°Ô∏è [OpenAI Assistants Basics](#chapter-7-openai-assistants-basics)  

üõë Setup w/ Azure OpenAI in [chapter 2](#chapter-2-setup-w-azure-openai)  

‚ó¶ Create a simple assistant  
‚ó¶ `ai chat assistant create --name MyAssistant`  
‚ó¶ `ai config @assistant.id`  

‚ó¶ Threads ...  
‚ó¶ `ai chat --interactive`  
‚ó¶ `ai chat --interactive --thread-id ID` (from previous chat)  

‚ó¶ `ai chat --question "..." --output-thread-id myNewThread.txt`  
‚ó¶ `ai chat --question "..." --thread-id @myNewThread.txt`  
‚ó¶ `ai chat --interactive --thread-id @myNewThread.txt --output-chat-history history.jsonl`  

‚ó¶ Generate code for using assistants  
‚ó¶ `ai dev new list asst`  
‚ó¶ `ai dev new openai-asst-streaming --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... similar to console apps generated in earlier chapters  
‚ó¶ ... see how the LLM sends back citations to the helper class  
‚ó¶ ... see how the helper class processes the citations  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

‚ó¶ Delete the assistant  
‚ó¶ `ai chat assistant delete`  
‚ó¶ `ai config --clear assistant.id`  

## CHAPTER 8: OpenAI Assistants w/ Code Interpreter

‚û°Ô∏è [OpenAI Assistants w/ Code Interpreter](#chapter-8-openai-assistants-w-code-interpreter)  

üõë Setup w/ Azure OpenAI in [chapter 2](#chapter-2-setup-w-azure-openai)  

‚ó¶ Create or update an assistant with a code interpreter  
‚ó¶ `ai chat assistant create --name MyCodeAssistant --code-interpreter`  
‚ó¶ `ai chat assistant update --code-interpreter`  

‚ó¶ Use the code interpreter in the assistant  
‚ó¶ `ai chat --interactive --question "how many e's are there in the pledge of allegiance?"`  
‚ó¶ ... `how'd you do that?`  
‚ó¶ ... `show me the code`  

‚ó¶ Generate code for using code interpreters  
‚ó¶ `ai dev new openai-asst-streaming-with-code --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... similar to console apps generated in earlier chapters  
‚ó¶ ... see how the LLM sends back info on the code created to the helper class  
‚ó¶ ... see how the helper class processes those responses  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

‚ó¶ Delete the assistant  
‚ó¶ `ai chat assistant delete`  
‚ó¶ `ai config --clear assistant.id`  

## CHAPTER 9: OpenAI Assistants w/ Function Calling

‚û°Ô∏è [OpenAI Assistants w/ Function Calling](#chapter-9-openai-assistants-w-function-calling)  

üõë Setup w/ Azure OpenAI in [chapter 2](#chapter-2-setup-w-azure-openai)  

‚ó¶ Create or update an assistant for use with function calling  
‚ó¶ `ai chat assistant create --name MyFunctionAssistant`  

‚ó¶ Use the assistant with function calling, via built-in CLI functions  
‚ó¶ ... This is similar to Chapter 4's chat completions w/ function calling  
‚ó¶ `ai chat --user "What time is it?" --built-in-functions`  
‚ó¶ `ai chat --user "What is in the README.md file?" --built-in-functions`  
‚ó¶ `ai chat --user "Save the pledge of allegiance to 'pledge.txt'" --built-in-functions`  

‚ó¶ Generating code for function calling  
‚ó¶ `ai dev new list function`  
‚ó¶ `ai dev new openai-asst-streaming-with-functions --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... builds on chapter 7's console app  
‚ó¶ ... see how functions are defined, given to "function factory"  
‚ó¶ ... in helper class, see how functions are given to the LLM  
‚ó¶ ... see how the LLM streams back the function call requests  
‚ó¶ ... see how the helper class processes the function call responses  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

‚ó¶ Delete the assistant  
‚ó¶ `ai chat assistant delete`  
‚ó¶ `ai config --clear assistant.id`  

## CHAPTER 10: OpenAI Assistants w/ File Search

‚û°Ô∏è [OpenAI Assistants w/ File Search](#chapter-10-openai-assistants-w-file-search)  

üõë Setup w/ Azure OpenAI in [chapter 2](#chapter-2-setup-w-azure-openai)  

‚ó¶ Create or update an assistant for use with file search  
‚ó¶ `ai chat assistant create --name MyFileAssistant --files "**/*.md"`  
‚ó¶ `ai chat assistant update --files "**/*.txt"` or `--files "**/*.cs"` or `--files "**/*.ts"` ...  

‚ó¶ Use the assistant with file search  
‚ó¶ `ai chat --user "..."`  
‚ó¶ `ai chat --user "..." --interactive`  

‚ó¶ Generating code for file search  
‚ó¶ `ai dev new list file`  
‚ó¶ `ai dev new openai-asst-streaming-with-file-search --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... builds on chapter 7's console app  
‚ó¶ ... see how the LLM sends back citations to the helper class  
‚ó¶ ... see how the helper class processes the citations  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

‚ó¶ Delete the assistant  
‚ó¶ `ai chat assistant delete`  
‚ó¶ `ai config --clear assistant.id`  

## CHAPTER 11: Setup w/ GitHub Model Marketplace

‚û°Ô∏è [Setup w/ GitHub Model Marketplace](#chapter-11-setup-w-github-model-marketplace)  

‚ó¶ https://github.com/marketplace/models/  
‚ó¶ Discuss how this is similar to Azure AI Model Catalog in chapter 14  
‚ó¶ Discuss how this is similar to OpenAI API in chapters 3-5  

‚ó¶ `ai init github`  
‚ó¶ Enter your GitHub personal access token from https://github.com/settings/tokens  
‚ó¶ Enter the model you want to use (e.g. `gpt-4o`, `gpt-4o-mini`, `Mistral-large-2407`, etc.)  

## CHAPTER 12: GitHub Model Chat Completion Basics

‚û°Ô∏è [Chat Completion Basics](#chapter-12-github-model-chat-completion-basics)  

üõë Setup w/ GitHub Model Marketplace in [chapter 11](#chapter-11-setup-w-github-model-marketplace)  

‚ó¶ Use the model in chat completions  
‚ó¶ `ai chat --user "What is the capital of France?"`  
‚ó¶ `ai chat --user "What is the population of the United States?" --interactive`  

‚ó¶ Use a different model in chat completions  
‚ó¶ `ai chat --interactive --model Mistral-large-2407` or `--model gpt-4o-mini` ...  
‚ó¶ OR: `ai config @chat.model`  
‚ó¶ ... `ai config --set chat.model gpt-4o` or `--set chat.model gpt-4o-mini` ...  

‚ó¶ Generate code for chat completions with GitHub models  
‚ó¶ `ai dev new list inference`  
‚ó¶ `ai dev new az-inference-chat-streaming --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... builds on previous chapters' console apps  
‚ó¶ ... gets connection info/secrets from environment variables  
‚ó¶ ... see how use of the Azure.AI.Inference namespace is similar/different from OpenAI  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

## CHAPTER 13: GitHub Model Chat Completions W/ Function Calling

‚û°Ô∏è [Chat Completions W/ Function Calling](#chapter-13-github-model-chat-completions-w-function-calling)  

üõë Setup w/ GitHub Model Marketplace in [chapter 11](#chapter-11-setup-w-github-model-marketplace)  

... üöß UNDER CONSTRUCTION ...  

## CHAPTER 14: Setup w/ AI Studio and the Model Catalog

‚û°Ô∏è [AI Studio and the Model Catalog](#chapter-14-setup-w-ai-studio-and-the-model-catalog)  

‚ó¶ https://ai.azure.com/explore/models  
‚ó¶ Discuss how this is similar to GitHub Model Marketplace in chapter 11  
‚ó¶ Discuss how this is similar to OpenAI API in chapters 3-5  

‚ó¶ Discuss how to deploy models to Azure AI Studio  
‚ó¶ HELP: https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models-serverless  

‚ó¶ `ai init inference`  
‚ó¶ Enter your Azure AI Inference endpoint  
‚ó¶ Enter your Azure AI Inference key  

## CHAPTER 15: AI Studio Chat Completions Basics

‚û°Ô∏è [Chat Completions Basics](#chapter-15-ai-studio-chat-completions-basics)  

üõë Setup w/ AI Studio and the Model Catalog in [chapter 14](#chapter-14-setup-w-ai-studio-and-the-model-catalog)  

‚ó¶ Use the model in chat completions  
‚ó¶ `ai chat --user "What is the capital of France?"`  
‚ó¶ `ai chat --user "What is the population of the United States?" --interactive`  

‚ó¶ Generate code for chat completions with AI Studio models  
‚ó¶ `ai dev new list inference`  
‚ó¶ `ai dev new az-inference-chat-streaming --csharp` or `--python` or `--javascript` ...  

‚ó¶ Go over what was generated in the console app  
‚ó¶ ... builds on previous chapters' console apps  
‚ó¶ ... gets connection info/secrets from environment variables  
‚ó¶ ... see how use of the Azure.AI.Inference namespace is similar/different from OpenAI  

‚ó¶ Install the dependencies  
‚ó¶ `dotnet restore` or `pip install -r requirements.txt` or `npm install` ...  

‚ó¶ Run the console app  
‚ó¶ `ai dev shell`  
‚ó¶ `dotnet run` or `python main.py` or `node main.js` ...  

## CHAPTER 16: AI Studio Chat Completions w/ Function Calling

‚û°Ô∏è [Chat Completions w/ Function Calling](#chapter-16-ai-studio-chat-completions-w-function-calling)  

üõë Setup w/ AI Studio and the Model Catalog in [chapter 14](#chapter-14-setup-w-ai-studio-and-the-model-catalog)  

... üöß UNDER CONSTRUCTION ...  

## CHAPTER 17: PHI-3 Models

‚û°Ô∏è [PHI-3 Models](#chapter-17-phi-3-models)  

...

## CHAPTER 18: ONNX Chat Completions

‚û°Ô∏è [ONNX Chat Completions](#chapter-18-onnx-chat-completions)

...

## CHAPTER 19: ONNX Chat Completions w/ Function Calling

‚û°Ô∏è [ONNX Chat Completions w/ Function Calling](#chapter-19-onnx-chat-completions-w-function-calling)  

...

## CHAPTER 20: Speech Synthesis

‚û°Ô∏è [Speech Synthesis](#chapter-20-speech-synthesis)  

...

## CHAPTER 21: Speech Recognition

‚û°Ô∏è [Speech Recognition](#chapter-21-speech-recognition)  

...

## CHAPTER 22: Speech Translation

‚û°Ô∏è [Speech Translation](#chapter-22-speech-translation)  

...

## CHAPTER 23: Speech Recognition w/ Keyword Spotting

‚û°Ô∏è [Speech Recognition w/ Keyword Spotting](#chapter-23-speech-recognition-w-keyword-spotting)  

...

## CHAPTER 24: Multi-Modal AI

‚û°Ô∏è [Multi-Modal AI](#chapter-24-multi-modal-ai)  

...

## CHAPTER 25: Chat Completions w/ Speech Input

‚û°Ô∏è [Chat Completions w/ Speech Input](#chapter-25-chat-completions-w-speech-input)  

...

## CHAPTER 26: Chat Completions w/ Speech Input and Output

‚û°Ô∏è [Chat Completions w/ Speech Input and Output](#chapter-26-chat-completions-w-speech-input-and-output)  

...

## CHAPTER 27: Chat Completions w/ Image Input

‚û°Ô∏è [Chat Completions w/ Image Input](#chapter-27-chat-completions-w-image-input)  

...

## CHAPTER 28: Chat Completions w/ Image Output

‚û°Ô∏è [Chat Completions w/ Image Output](#chapter-28-chat-completions-w-image-output)  

...

## CHAPTER 29: Semantic Kernel Basics

‚û°Ô∏è [Semantic Kernel Basics](#chapter-29-semantic-kernel-basics)  

...

## CHAPTER 30: Semantic Kernel w/ Function Calling

‚û°Ô∏è [Semantic Kernel w/ Function Calling](#chapter-30-semantic-kernel-w-function-calling)  

...

## CHAPTER 31: Semantic Kernel w/ Basic Agents

‚û°Ô∏è [Semantic Kernel w/ Basic Agents](#chapter-31-semantic-kernel-w-basic-agents)  

...

## CHAPTER 32: Semantic Kernel w/ Advanced Agents

‚û°Ô∏è [Semantic Kernel w/ Advanced Agents](#chapter-32-semantic-kernel-w-advanced-agents)  

...

